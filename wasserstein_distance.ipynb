{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9uGz1gPcS7AqDpMADE7/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtsizh/bottleneck-distance-for-sigma8/blob/main/wasserstein_distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Download datasets\n",
        "#@markdown Run this block of code to download our dataset to Google Colab.\n",
        "#@markdown If successful this code yields \n",
        "#@markdown * folder `alldata2` containing all data for further scripts\n",
        "#@markdown * file `alldata_large.zip` -- the same data zipped; not needed for scripts, but you may want to download it to your local machine\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "files = ['alldata.zip', 'alldata.z01', 'alldata.z02', 'alldata.z03']\n",
        "print('deleting old files if exist')\n",
        "!rm -rf alldata2\n",
        "!rm -f alldata_large.zip\n",
        "for f in files:\n",
        "  !rm -f {f}\n",
        "for i,f in enumerate(files):\n",
        "  print('downloading part ', i+1, ' of ', len(files))\n",
        "  #result = !curl -s -S https://raw.githubusercontent.com/mtsizh/bottleneck-distance-for-sigma8/main/{f} > /dev/null && echo \"TRUE\"\n",
        "  result = !wget -q https://raw.githubusercontent.com/mtsizh/bottleneck-distance-for-sigma8/main/{f} && echo \"1\" || echo \"0\"\n",
        "  if result == ['1']:\n",
        "    print('OK')\n",
        "  else:\n",
        "    raise Exception(\"ERROR WHILE DOWNLOADING DATA\")\n",
        "clear_output()\n",
        "print(\"DOWNLOAD SUCCESSFUL\")\n",
        "print(\"PARTS TO ZIP\")\n",
        "result = !zip -qq -F alldata.zip --out alldata_large.zip 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('OK')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE CREATING LARGE ZIP\")\n",
        "print(\"UNZIPPING\")\n",
        "result = !unzip -o -qq alldata_large.zip 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('OK')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE UNZIPPING\")\n",
        "print('cleaning')\n",
        "for f in files:\n",
        "  !rm -f {f}\n",
        "clear_output()\n",
        "print(\"ALL DATA DOWNLOADED AND UNPACKED\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SzMIc6iSgdh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install gudhi library with the following code (needed for persistence homology calculations)"
      ],
      "metadata": {
        "id": "jb2DFHrD_1O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ott-jax\n",
        "!pip install POT\n",
        "!pip install eagerpy\n",
        "!pip install gudhi"
      ],
      "metadata": {
        "id": "18noI2tO_0CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code calculates persistence intervals. Results are saved as `persistence.json` file. Computations are lengthy, please wait until the progressbar reaches 100%. For your convenience `persistence.json.zip` is created so that you can download intermediate data to your computer.\n",
        "\n",
        "If you want to suspend your work for a while: download the zip file and you can later reupload it to Google Colab, unzip with command `!unzip persistence.json.zip` and proceed your work."
      ],
      "metadata": {
        "id": "ReBsh2qSMj13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Folder with data (should be ok by default)\n",
        "root_folder = \"./alldata2\" #@param {type: \"string\"}\n",
        "#@markdown Choose mass filtering in % (0 to 100)\n",
        "remove_masses_lower_than = 0  #@param {type: \"slider\", min: 0, max: 100}\n",
        "remove_masses_higher_than = 100  #@param {type: \"slider\", min: 0, max: 100}\n",
        "#@markdown Choose random filtering in % (0 to 100)\n",
        "bootstrap_percent = 50  #@param {type: \"slider\", min: 0, max: 100}\n",
        "#@markdown File to save results, use JSON only! (should be ok by default)\n",
        "save_to = \"persistence.json\" #@param {type: \"string\"}\n",
        "\n",
        "if remove_masses_higher_than <= remove_masses_lower_than:\n",
        "  raise Exception(\"Upper masses limit should be larger then the lower limit\")\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gudhi\n",
        "from ipywidgets import IntProgress\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "def read_all_data(filename, bootstrap_percent=100, mass_filter=[0, 100]):\n",
        "  df = pd.read_csv(filename, sep=r'\\t', header=None, engine ='python')\n",
        "  df.drop(df.columns.difference([0,1,2,3]), axis=1, inplace=True)\n",
        "  df.rename(columns={0:'x', 1:'y', 2:'z', 3:'m'}, inplace=True)\n",
        "  min_m = df['m'].quantile(mass_filter[0]/100)\n",
        "  max_m = df['m'].quantile(mass_filter[1]/100)\n",
        "  df = df[df['m'].between(min_m, max_m)]\n",
        "  df.drop(['m'], axis=1, inplace=True)\n",
        "  all_arr = df.to_numpy()\n",
        "  return all_arr[np.random.choice(all_arr.shape[0], replace=False,\n",
        "                           size=all_arr.shape[0]*bootstrap_percent//100)]\n",
        "\n",
        "def get_persistence_intervals(point_set, dim):\n",
        "  alpha_complex = gudhi.AlphaComplex(points=point_set)\n",
        "  simplex_tree = alpha_complex.create_simplex_tree(default_filtration_value=False)\n",
        "  simplex_tree.compute_persistence()\n",
        "  persistence_intervals = simplex_tree.persistence_intervals_in_dimension(dim)\n",
        "  return persistence_intervals\n",
        "\n",
        "dat_files = [y for x in os.walk(root_folder) for y in glob(os.path.join(x[0], '*.dat'))]\n",
        "reg_expr = '.*\\/([0-9]+)groups_([0-9]+)_new.dat'\n",
        "parsed = [{'filename': f, \n",
        "           'sigma': int(re.match(reg_expr, f).group(1)), \n",
        "           'red_shift': int(re.match(reg_expr, f).group(2))\n",
        "           } for f in dat_files]\n",
        "all_data = pd.DataFrame(columns=[\"sigma8*10\", \"red_shift\", \"dimension\", \"born\", \"persists\"])\n",
        "\n",
        "bar = IntProgress(min=0, max=len(parsed))\n",
        "bar.value = 0\n",
        "display.display(bar)\n",
        "\n",
        "for f in parsed:\n",
        "  data = read_all_data(f['filename'], bootstrap_percent, \n",
        "                       [remove_masses_lower_than, remove_masses_higher_than])\n",
        "  for dim in [0, 1, 2]:\n",
        "    I = get_persistence_intervals(data, dim)\n",
        "    df = {'sigma8*10': f['sigma'], \n",
        "          'red_shift': f['red_shift'], \n",
        "          'dimension': dim,\n",
        "          'born': I[:,0].tolist(),\n",
        "          'dies': I[:,1].tolist(),\n",
        "          'persists': (I[:,1] - I[:,0]).tolist()}\n",
        "    all_data = all_data.append(df, ignore_index = True)\n",
        "  bar.value += 1 \n",
        "\n",
        "all_data.to_json(save_to)\n",
        "print(\"JSON creation complete!\")\n",
        "\n",
        "result =!zip -qq -r {save_to}.zip {save_to} 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('zipped')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE CREATING ZIP\")"
      ],
      "metadata": {
        "id": "VO_MTMmMrAV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code visualizes results of the previous calculation."
      ],
      "metadata": {
        "id": "_XMnGMJ_3lGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown File to load data (should be ok by default)\n",
        "read_from = \"persistence.json\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "from IPython import display\n",
        "\n",
        "df = pd.read_json(read_from)\n",
        "df = df.groupby(['sigma8*10', 'red_shift', 'dimension']).agg(lambda x: sum(list(x), [])).reset_index()\n",
        "\n",
        "\n",
        "def plot_by_params(dim, sig):\n",
        "  plt.figure(figsize=(12,7))\n",
        "  sns.set_context(\"notebook\", font_scale=1.5)\n",
        "\n",
        "  plt.title(\"$\\sigma_8 = \"+str(sig/10)+\" $, dimension: \"+str(dim))\n",
        "  plt.xlabel(\"Birth\")\n",
        "  plt.ylabel(\"Persistence\")\n",
        "\n",
        "  pick_df = df[(df['sigma8*10'] == sig) & (df['dimension'] == dim)]\n",
        "  r_shifts = pick_df['red_shift'].unique()\n",
        "  cmap = plt.cm.get_cmap('plasma')\n",
        "\n",
        "  for idx,red_shift in enumerate(r_shifts):\n",
        "    X = np.array(pick_df[pick_df['red_shift'] == red_shift]['born'].values[0])\n",
        "    Y = np.array(pick_df[pick_df['red_shift'] == red_shift]['persists'].values[0])\n",
        "    plt.scatter(X, Y, color=cmap(idx/len(r_shifts)), label=\"red shift: \"+str(red_shift))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def make_widget(field):\n",
        "  return widgets.Dropdown(\n",
        "    options=df[field].unique(),\n",
        "    #value='2',\n",
        "    description=field,\n",
        "    disabled=False,\n",
        "  )\n",
        "\n",
        "from ipywidgets import interactive_output\n",
        "\n",
        "w = [make_widget(field) for field in ['dimension', 'sigma8*10']]\n",
        "ui = widgets.HBox(w)\n",
        "out = widgets.interactive_output(plot_by_params, {'dim': w[0], \n",
        "                                                  'sig': w[1]})\n",
        "display.display(ui, out)\n"
      ],
      "metadata": {
        "id": "yDTn2wfXN14I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code calculates distances between pairs of simulations. Results are stored as a json file. For your convenience archive is created as well.\n",
        "\n",
        "Warning: takes a lot of time."
      ],
      "metadata": {
        "id": "ITRbeX520Ki8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown File to load data (should be ok by default)\n",
        "read_from = \"persistence.json\" #@param {type: \"string\"}\n",
        "#@markdown Choose metric $W_p$ (p-Wasserstein) or $W_\\infty$ (Bottleneck distance)\n",
        "metric_to_use = \"p-Wasserstein\" #@param [\"Bottleneck distance\", \"p-Wasserstein\"] {allow-input: false}\n",
        "#@markdown If you choose p-Wasserstein set the order p\n",
        "wasserstein_order = 1.0  #@param {type: \"slider\", min: 1.0, max: 5.0}\n",
        "#@markdown File to save results, use JSON only! (should be ok by default)\n",
        "save_to = \"distances.json\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gudhi\n",
        "#import gudhi.hera\n",
        "import gudhi.wasserstein\n",
        "from ipywidgets import IntProgress\n",
        "from IPython import display\n",
        "import tensorflow as tf\n",
        "\n",
        "df = pd.read_json(read_from)\n",
        "result = pd.DataFrame(columns=[\"Dsigma8*10\", \"red_shift\", \"dimension\", \"distances\"])\n",
        "\n",
        "bar = IntProgress(min=0, max=len(df.index))\n",
        "bar.value = 0\n",
        "bar1 = IntProgress(min=0, max=len(df.index))\n",
        "bar1.value = 0\n",
        "display.display(bar, bar1)\n",
        "\n",
        "\n",
        "for r_shift in df['red_shift'].unique():\n",
        "  df1 = df[df['red_shift'] == r_shift]\n",
        "  for dimension in df1['dimension'].unique():\n",
        "    df2 = df1[df1['dimension'] == dimension]\n",
        "    distances = {}\n",
        "    for idx1 in range(len(df2.index)):\n",
        "      I1 = np.transpose([df2.iloc[idx1]['born'], df2.iloc[idx1]['dies']]).astype(float)\n",
        "      I1 = tf.convert_to_tensor(I1, dtype=float)\n",
        "      sigma81 = df2.iloc[idx1]['sigma8*10']\n",
        "      bar1.max = len(df2.index)\n",
        "      bar1.value = 0\n",
        "      for idx2 in range(len(df2.index)):\n",
        "        bar1.value += 1\n",
        "        if idx2 <= idx1:\n",
        "          continue\n",
        "        I2 = np.transpose([df2.iloc[idx2]['born'], df2.iloc[idx2]['dies']]).astype(float)\n",
        "        I2 = tf.convert_to_tensor(I2, dtype=float)\n",
        "        sigma82 = df2.iloc[idx2]['sigma8*10']\n",
        "        #print(I1.shape, I2.shape)\n",
        "        if metric_to_use == \"p-Wasserstein\":\n",
        "          #dist = float(gudhi.hera.wasserstein_distance(np.array(I1, dtype=float), \n",
        "          #                                             np.array(I2, dtype=float)))\n",
        "          dist = float(gudhi.wasserstein.wasserstein_distance(I1, \n",
        "                                                              I2,\n",
        "                                                              matching=False,\n",
        "                                                              enable_autodiff=True, \n",
        "                                                              keep_essential_parts=False,\n",
        "                                                              order=wasserstein_order))\n",
        "        else:\n",
        "          dist = float(gudhi.bottleneck_distance(I1, I2))\n",
        "        dsigma = np.abs(sigma81 - sigma82)\n",
        "        if not dsigma in distances:\n",
        "          distances[dsigma] = []\n",
        "        distances[dsigma].append(dist)\n",
        "      bar.value += 1\n",
        "    for dsigma in distances:\n",
        "      row = {'Dsigma8*10': dsigma, \n",
        "             'red_shift': r_shift, \n",
        "             'dimension': dimension,\n",
        "             'distances': distances[dsigma]}\n",
        "      result = result.append(row, ignore_index = True)\n",
        "\n",
        "result.to_json(save_to)\n",
        "print(\"JSON creation complete!\")\n",
        "\n",
        "result =!zip -qq -r {save_to}.zip {save_to} 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('zipped')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE CREATING ZIP\")"
      ],
      "metadata": {
        "id": "aGOyykSJXHVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install KDEpy library with the following code (needed for probability density estimation, specifically finding kernel width by Silverman's rule)"
      ],
      "metadata": {
        "id": "ipAPRiUWxs-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install KDEpy"
      ],
      "metadata": {
        "id": "UlaVXrJqslIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code visualizes results of the previous calculation."
      ],
      "metadata": {
        "id": "5K0KgGS_0Fho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown File to load data (should be ok by default)\n",
        "read_from = \"distances.json\" #@param {type: \"string\"}\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "from matplotlib.patches import Patch\n",
        "from matplotlib.lines import Line2D\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from KDEpy import FFTKDE\n",
        "\n",
        "df = pd.read_json(read_from)\n",
        "\n",
        "legend_elements = [\n",
        "                    Line2D([0], [0], marker='o', color='w', \n",
        "                          label='$0$ homologies',\n",
        "                          markerfacecolor='r', markersize=10),\n",
        "                   Line2D([0], [0], marker='o', color='w', \n",
        "                          label='$1$ homologies',\n",
        "                          markerfacecolor='b', markersize=10),\n",
        "                  Line2D([0], [0], marker='o', color='w', \n",
        "                          label='$2$ homologies',\n",
        "                          markerfacecolor='g', markersize=10)\n",
        "                   ]\n",
        "\n",
        "def plot_data(ax, data, box_color='b', shift=0.0):\n",
        "  ax.set_xlabel(\"$\\Delta \\sigma_8$\")\n",
        "  ax.set_ylabel(\"$W$ distance\")\n",
        "  y = data['distances'].tolist()\n",
        "  x = data['Dsigma8*10'].tolist()  \n",
        "  y = [y[i] for i in np.argsort(x)]\n",
        "  xu = np.sort(x)/10\n",
        "  medians = [np.median(yd) for yd in y]\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
        "  ax.boxplot(y, \n",
        "              showmeans=True, positions=xu + shift, widths=0.006,\n",
        "              boxprops=dict(color=box_color),\n",
        "              whiskerprops=dict(color=box_color),\n",
        "              capprops=dict(color=box_color),\n",
        "              flierprops=dict(color=box_color, markeredgecolor=box_color))\n",
        "  ax.plot(xu + shift, medians, c=box_color)\n",
        "  ax.set_xlim(np.min(xu)-0.025, np.max(xu)+0.025)\n",
        "  ax.set_navigate(False)\n",
        "  ax.set_xticks(xu)\n",
        "  ax.set_xticklabels(xu)\n",
        "\n",
        "def plot_pdf(ax, data, pdf_color, limits, label):\n",
        "  kde = FFTKDE(bw='silverman', kernel='gaussian')\n",
        "  kde.fit(data)(None)\n",
        "  b_w = kde.bw\n",
        "  kde = KernelDensity(bandwidth=b_w, kernel='gaussian')\n",
        "  kde.fit(data.reshape(-1, 1))\n",
        "  x_d = np.linspace(limits[0], limits[1], 1001)\n",
        "  logprob = kde.score_samples(x_d.reshape(-1, 1))\n",
        "  plt.plot(data, np.full_like(data, 0.0), markeredgewidth=1, color=pdf_color)\n",
        "  ax.set_title('Pdf approximation')\n",
        "  ax.set_xlabel('$W$ distance for Homologies', fontsize=18)\n",
        "  ax.set_ylabel('Probability density function', fontsize=18)\n",
        "  ax.fill_between(x_d, np.exp(logprob), alpha=0.3, label=label, color=pdf_color)\n",
        "\n",
        "def plot_by_params(red_s, Dsigma8):\n",
        "  sns.set_context(\"notebook\", font_scale=1.5)\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(20,6))\n",
        "  df_filtered = df[df['red_shift'] == red_s]\n",
        "  dims = np.unique(df_filtered['dimension'])\n",
        "  colors = {0:'r', 1:'b', 2:'g'}\n",
        "  for d in dims:\n",
        "    data = df_filtered[df_filtered['dimension'] == d]\n",
        "    plot_data(axs[0], data, \n",
        "              box_color=colors[d],\n",
        "              shift={0:-0.005, 1:0.0, 2:+0.005}[d])\n",
        "  axs[0].legend(handles=legend_elements, loc='upper left', prop={'size': 12})\n",
        "  Dsigma810 = int(Dsigma8*10)\n",
        "  df_filtered = df_filtered[df_filtered['Dsigma8*10'] == Dsigma810]\n",
        "  limits=[np.min(df_filtered['distances'].tolist()), np.max(df_filtered['distances'].tolist())]\n",
        "  for d in dims:\n",
        "    data = df_filtered[df_filtered['dimension'] == d]['distances']\n",
        "    plot_pdf(axs[1], np.array(data.tolist()[0]), pdf_color=colors[d], limits=limits, label=str(d)+\" homology\")  \n",
        "  axs[1].legend()\n",
        "  plt.show()\n",
        "  \n",
        "import ipywidgets as widgets\n",
        "\n",
        "def make_widget(options, descr):\n",
        "  return widgets.Dropdown(\n",
        "    options=options,\n",
        "    #value='2',\n",
        "    description=descr,\n",
        "    disabled=False,\n",
        "  )\n",
        "\n",
        "from ipywidgets import interactive_output\n",
        "\n",
        "w = [make_widget(np.unique(df['red_shift']), 'red shift'),\n",
        "     make_widget(np.unique(df['Dsigma8*10'])/10, 'Delta sigma8 x 10$')]\n",
        "ui = widgets.HBox(w)\n",
        "out = widgets.interactive_output(plot_by_params, {'red_s': w[0],\n",
        "                                                  'Dsigma8': w[1]})\n",
        "display.display(ui, out)\n",
        "\n"
      ],
      "metadata": {
        "id": "DXZQKPTUo0OU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}