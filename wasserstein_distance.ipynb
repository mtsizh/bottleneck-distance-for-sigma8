{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPozVKgxVtbVPcmZAGH5wxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtsizh/bottleneck-distance-for-sigma8/blob/main/wasserstein_distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Download datasets\n",
        "#@markdown Run this block of code to download our dataset to Google Colab.\n",
        "#@markdown If successful this code yields \n",
        "#@markdown * folder `alldata2` containing all data for further scripts\n",
        "#@markdown * file `alldata_large.zip` -- the same data zipped; not needed for scripts, but you may want to download it to your local machine\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "files = ['alldata.zip', 'alldata.z01', 'alldata.z02', 'alldata.z03']\n",
        "print('deleting old files if exist')\n",
        "!rm -rf alldata2\n",
        "!rm -f alldata_large.zip\n",
        "for f in files:\n",
        "  !rm -f {f}\n",
        "for i,f in enumerate(files):\n",
        "  print('downloading part ', i, ' of ', len(files))\n",
        "  #result = !curl -s -S https://raw.githubusercontent.com/mtsizh/bottleneck-distance-for-sigma8/main/{f} > /dev/null && echo \"TRUE\"\n",
        "  result = !wget -q https://raw.githubusercontent.com/mtsizh/bottleneck-distance-for-sigma8/main/{f} && echo \"1\" || echo \"0\"\n",
        "  if result == ['1']:\n",
        "    print('OK')\n",
        "  else:\n",
        "    raise Exception(\"ERROR WHILE DOWNLOADING DATA\")\n",
        "clear_output()\n",
        "print(\"DOWNLOAD SUCCESSFUL\")\n",
        "print(\"PARTS TO ZIP\")\n",
        "result = !zip -qq -F alldata.zip --out alldata_large.zip 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('OK')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE CREATING LARGE ZIP\")\n",
        "print(\"UNZIPPING\")\n",
        "result = !unzip -o -qq alldata_large.zip 2>/dev/null && echo \"1\" || echo \"0\"\n",
        "if result == ['1']:\n",
        "  print('OK')\n",
        "else:\n",
        "  raise Exception(\"ERROR WHILE UNZIPPING\")\n",
        "print('cleaning')\n",
        "for f in files:\n",
        "  !rm -f {f}\n",
        "clear_output()\n",
        "print(\"ALL DATA DOWNLOADED AND UNPACKED\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SzMIc6iSgdh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740c99ac-974c-4096-faf9-f6c56fdbd7ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALL DATA DOWNLOADED AND UNPACKED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "root_folder = \"./alldata2\"\n",
        "\n",
        "dat_files = [y for x in os.walk(root_folder) for y in glob(os.path.join(x[0], '*.dat'))]\n",
        "reg_expr = '.*\\/([0-9]+)groups_([0-9]+)_new.dat'\n",
        "parsed = [{'filename': f, \n",
        "           'sigma': int(re.match(reg_expr, f).group(1)), \n",
        "           'red_shift': int(re.match(reg_expr, f).group(2))\n",
        "           } for f in dat_files]\n",
        "\n",
        "def read_all_data(filename, bootstrap_percent=100, mass_filter=[0, 100]):\n",
        "  df = pd.read_csv(filename, sep=r'\\t', header=None, engine ='python')\n",
        "  df.drop(df.columns.difference([0,1,2,3]), axis=1, inplace=True)\n",
        "  df.rename(columns={0:'x', 1:'y', 2:'z', 3:'m'}, inplace=True)\n",
        "  #x = df.apply(lambda s: pd.to_numeric(s, errors='coerce').notnull().all())\n",
        "  return x\n",
        "\n",
        "#@markdown Choose filtering in % (0 to 100)\n",
        "remove_masses_lower_than = 0  #@param {type: \"slider\", min: 0, max: 100}\n",
        "remove_masses_higher_than = 100  #@param {type: \"slider\", min: 0, max: 100}\n",
        "bootstrap_percent = 100  #@param {type: \"slider\", min: 0, max: 100}\n",
        "\n",
        "\n",
        "for y in parsed:\n",
        "  print(read_all_data(y['filename']))"
      ],
      "metadata": {
        "id": "VO_MTMmMrAV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}